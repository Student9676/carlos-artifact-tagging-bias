{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Version 2.2 concatenates all texts by only keeping sentences where bias is present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas==2.2.3 in /opt/homebrew/anaconda3/envs/carlos/lib/python3.12/site-packages (from -r ../requirements.txt (line 1)) (2.2.3)\n",
      "Requirement already satisfied: xlsxwriter==3.2.0 in /opt/homebrew/anaconda3/envs/carlos/lib/python3.12/site-packages (from -r ../requirements.txt (line 2)) (3.2.0)\n",
      "Requirement already satisfied: regex==2024.9.11 in /opt/homebrew/anaconda3/envs/carlos/lib/python3.12/site-packages (from -r ../requirements.txt (line 3)) (2024.9.11)\n",
      "Requirement already satisfied: openpyxl==3.1.5 in /opt/homebrew/anaconda3/envs/carlos/lib/python3.12/site-packages (from -r ../requirements.txt (line 4)) (3.1.5)\n",
      "Requirement already satisfied: pysbd==0.3.4 in /opt/homebrew/anaconda3/envs/carlos/lib/python3.12/site-packages (from -r ../requirements.txt (line 5)) (0.3.4)\n",
      "Requirement already satisfied: transformers==4.45.2 in /opt/homebrew/anaconda3/envs/carlos/lib/python3.12/site-packages (from -r ../requirements.txt (line 6)) (4.45.2)\n",
      "Requirement already satisfied: torch==2.5.0 in /opt/homebrew/anaconda3/envs/carlos/lib/python3.12/site-packages (from -r ../requirements.txt (line 7)) (2.5.0)\n",
      "Requirement already satisfied: scikit-learn==1.5.2 in /opt/homebrew/anaconda3/envs/carlos/lib/python3.12/site-packages (from -r ../requirements.txt (line 8)) (1.5.2)\n",
      "Requirement already satisfied: datasets==3.0.1 in /opt/homebrew/anaconda3/envs/carlos/lib/python3.12/site-packages (from -r ../requirements.txt (line 9)) (3.0.1)\n",
      "Requirement already satisfied: seaborn==0.13.2 in /opt/homebrew/anaconda3/envs/carlos/lib/python3.12/site-packages (from -r ../requirements.txt (line 10)) (0.13.2)\n",
      "Requirement already satisfied: accelerate==1.0.0 in /opt/homebrew/anaconda3/envs/carlos/lib/python3.12/site-packages (from -r ../requirements.txt (line 11)) (1.0.0)\n",
      "Requirement already satisfied: ipykernel==6.29.5 in /opt/homebrew/anaconda3/envs/carlos/lib/python3.12/site-packages (from -r ../requirements.txt (line 12)) (6.29.5)\n",
      "Requirement already satisfied: torchvision==0.20.0 in /opt/homebrew/anaconda3/envs/carlos/lib/python3.12/site-packages (from -r ../requirements.txt (line 13)) (0.20.0)\n",
      "Requirement already satisfied: torchaudio==2.5.0 in /opt/homebrew/anaconda3/envs/carlos/lib/python3.12/site-packages (from -r ../requirements.txt (line 14)) (2.5.0)\n",
      "Requirement already satisfied: tensorboardX==2.6.2.2 in /opt/homebrew/anaconda3/envs/carlos/lib/python3.12/site-packages (from -r ../requirements.txt (line 15)) (2.6.2.2)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /opt/homebrew/anaconda3/envs/carlos/lib/python3.12/site-packages (from pandas==2.2.3->-r ../requirements.txt (line 1)) (2.0.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/homebrew/anaconda3/envs/carlos/lib/python3.12/site-packages (from pandas==2.2.3->-r ../requirements.txt (line 1)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/homebrew/anaconda3/envs/carlos/lib/python3.12/site-packages (from pandas==2.2.3->-r ../requirements.txt (line 1)) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/homebrew/anaconda3/envs/carlos/lib/python3.12/site-packages (from pandas==2.2.3->-r ../requirements.txt (line 1)) (2024.2)\n",
      "Requirement already satisfied: et-xmlfile in /opt/homebrew/anaconda3/envs/carlos/lib/python3.12/site-packages (from openpyxl==3.1.5->-r ../requirements.txt (line 4)) (2.0.0)\n",
      "Requirement already satisfied: filelock in /opt/homebrew/anaconda3/envs/carlos/lib/python3.12/site-packages (from transformers==4.45.2->-r ../requirements.txt (line 6)) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/homebrew/anaconda3/envs/carlos/lib/python3.12/site-packages (from transformers==4.45.2->-r ../requirements.txt (line 6)) (0.26.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/homebrew/anaconda3/envs/carlos/lib/python3.12/site-packages (from transformers==4.45.2->-r ../requirements.txt (line 6)) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/homebrew/anaconda3/envs/carlos/lib/python3.12/site-packages (from transformers==4.45.2->-r ../requirements.txt (line 6)) (6.0.2)\n",
      "Requirement already satisfied: requests in /opt/homebrew/anaconda3/envs/carlos/lib/python3.12/site-packages (from transformers==4.45.2->-r ../requirements.txt (line 6)) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/homebrew/anaconda3/envs/carlos/lib/python3.12/site-packages (from transformers==4.45.2->-r ../requirements.txt (line 6)) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /opt/homebrew/anaconda3/envs/carlos/lib/python3.12/site-packages (from transformers==4.45.2->-r ../requirements.txt (line 6)) (0.20.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/homebrew/anaconda3/envs/carlos/lib/python3.12/site-packages (from transformers==4.45.2->-r ../requirements.txt (line 6)) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/homebrew/anaconda3/envs/carlos/lib/python3.12/site-packages (from torch==2.5.0->-r ../requirements.txt (line 7)) (4.12.2)\n",
      "Requirement already satisfied: networkx in /opt/homebrew/anaconda3/envs/carlos/lib/python3.12/site-packages (from torch==2.5.0->-r ../requirements.txt (line 7)) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /opt/homebrew/anaconda3/envs/carlos/lib/python3.12/site-packages (from torch==2.5.0->-r ../requirements.txt (line 7)) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /opt/homebrew/anaconda3/envs/carlos/lib/python3.12/site-packages (from torch==2.5.0->-r ../requirements.txt (line 7)) (2024.6.1)\n",
      "Requirement already satisfied: setuptools in /opt/homebrew/anaconda3/envs/carlos/lib/python3.12/site-packages (from torch==2.5.0->-r ../requirements.txt (line 7)) (75.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /opt/homebrew/anaconda3/envs/carlos/lib/python3.12/site-packages (from torch==2.5.0->-r ../requirements.txt (line 7)) (1.13.1)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /opt/homebrew/anaconda3/envs/carlos/lib/python3.12/site-packages (from scikit-learn==1.5.2->-r ../requirements.txt (line 8)) (1.14.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/homebrew/anaconda3/envs/carlos/lib/python3.12/site-packages (from scikit-learn==1.5.2->-r ../requirements.txt (line 8)) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/homebrew/anaconda3/envs/carlos/lib/python3.12/site-packages (from scikit-learn==1.5.2->-r ../requirements.txt (line 8)) (3.5.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /opt/homebrew/anaconda3/envs/carlos/lib/python3.12/site-packages (from datasets==3.0.1->-r ../requirements.txt (line 9)) (17.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/homebrew/anaconda3/envs/carlos/lib/python3.12/site-packages (from datasets==3.0.1->-r ../requirements.txt (line 9)) (0.3.8)\n",
      "Requirement already satisfied: xxhash in /opt/homebrew/anaconda3/envs/carlos/lib/python3.12/site-packages (from datasets==3.0.1->-r ../requirements.txt (line 9)) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in /opt/homebrew/anaconda3/envs/carlos/lib/python3.12/site-packages (from datasets==3.0.1->-r ../requirements.txt (line 9)) (0.70.16)\n",
      "Requirement already satisfied: aiohttp in /opt/homebrew/anaconda3/envs/carlos/lib/python3.12/site-packages (from datasets==3.0.1->-r ../requirements.txt (line 9)) (3.10.10)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in /opt/homebrew/anaconda3/envs/carlos/lib/python3.12/site-packages (from seaborn==0.13.2->-r ../requirements.txt (line 10)) (3.9.2)\n",
      "Requirement already satisfied: psutil in /opt/homebrew/anaconda3/envs/carlos/lib/python3.12/site-packages (from accelerate==1.0.0->-r ../requirements.txt (line 11)) (6.1.0)\n",
      "Requirement already satisfied: appnope in /opt/homebrew/anaconda3/envs/carlos/lib/python3.12/site-packages (from ipykernel==6.29.5->-r ../requirements.txt (line 12)) (0.1.4)\n",
      "Requirement already satisfied: comm>=0.1.1 in /opt/homebrew/anaconda3/envs/carlos/lib/python3.12/site-packages (from ipykernel==6.29.5->-r ../requirements.txt (line 12)) (0.2.2)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in /opt/homebrew/anaconda3/envs/carlos/lib/python3.12/site-packages (from ipykernel==6.29.5->-r ../requirements.txt (line 12)) (1.8.7)\n",
      "Requirement already satisfied: ipython>=7.23.1 in /opt/homebrew/anaconda3/envs/carlos/lib/python3.12/site-packages (from ipykernel==6.29.5->-r ../requirements.txt (line 12)) (8.29.0)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in /opt/homebrew/anaconda3/envs/carlos/lib/python3.12/site-packages (from ipykernel==6.29.5->-r ../requirements.txt (line 12)) (8.6.3)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /opt/homebrew/anaconda3/envs/carlos/lib/python3.12/site-packages (from ipykernel==6.29.5->-r ../requirements.txt (line 12)) (5.7.2)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in /opt/homebrew/anaconda3/envs/carlos/lib/python3.12/site-packages (from ipykernel==6.29.5->-r ../requirements.txt (line 12)) (0.1.7)\n",
      "Requirement already satisfied: nest-asyncio in /opt/homebrew/anaconda3/envs/carlos/lib/python3.12/site-packages (from ipykernel==6.29.5->-r ../requirements.txt (line 12)) (1.6.0)\n",
      "Requirement already satisfied: pyzmq>=24 in /opt/homebrew/anaconda3/envs/carlos/lib/python3.12/site-packages (from ipykernel==6.29.5->-r ../requirements.txt (line 12)) (26.2.0)\n",
      "Requirement already satisfied: tornado>=6.1 in /opt/homebrew/anaconda3/envs/carlos/lib/python3.12/site-packages (from ipykernel==6.29.5->-r ../requirements.txt (line 12)) (6.4.1)\n",
      "Requirement already satisfied: traitlets>=5.4.0 in /opt/homebrew/anaconda3/envs/carlos/lib/python3.12/site-packages (from ipykernel==6.29.5->-r ../requirements.txt (line 12)) (5.14.3)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/homebrew/anaconda3/envs/carlos/lib/python3.12/site-packages (from torchvision==0.20.0->-r ../requirements.txt (line 13)) (11.0.0)\n",
      "Requirement already satisfied: protobuf>=3.20 in /opt/homebrew/anaconda3/envs/carlos/lib/python3.12/site-packages (from tensorboardX==2.6.2.2->-r ../requirements.txt (line 15)) (4.25.3)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/homebrew/anaconda3/envs/carlos/lib/python3.12/site-packages (from sympy==1.13.1->torch==2.5.0->-r ../requirements.txt (line 7)) (1.3.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /opt/homebrew/anaconda3/envs/carlos/lib/python3.12/site-packages (from aiohttp->datasets==3.0.1->-r ../requirements.txt (line 9)) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/homebrew/anaconda3/envs/carlos/lib/python3.12/site-packages (from aiohttp->datasets==3.0.1->-r ../requirements.txt (line 9)) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/homebrew/anaconda3/envs/carlos/lib/python3.12/site-packages (from aiohttp->datasets==3.0.1->-r ../requirements.txt (line 9)) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/homebrew/anaconda3/envs/carlos/lib/python3.12/site-packages (from aiohttp->datasets==3.0.1->-r ../requirements.txt (line 9)) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/homebrew/anaconda3/envs/carlos/lib/python3.12/site-packages (from aiohttp->datasets==3.0.1->-r ../requirements.txt (line 9)) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in /opt/homebrew/anaconda3/envs/carlos/lib/python3.12/site-packages (from aiohttp->datasets==3.0.1->-r ../requirements.txt (line 9)) (1.16.0)\n",
      "Requirement already satisfied: decorator in /opt/homebrew/anaconda3/envs/carlos/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel==6.29.5->-r ../requirements.txt (line 12)) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/homebrew/anaconda3/envs/carlos/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel==6.29.5->-r ../requirements.txt (line 12)) (0.19.1)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in /opt/homebrew/anaconda3/envs/carlos/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel==6.29.5->-r ../requirements.txt (line 12)) (3.0.48)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /opt/homebrew/anaconda3/envs/carlos/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel==6.29.5->-r ../requirements.txt (line 12)) (2.18.0)\n",
      "Requirement already satisfied: stack-data in /opt/homebrew/anaconda3/envs/carlos/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel==6.29.5->-r ../requirements.txt (line 12)) (0.6.3)\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/homebrew/anaconda3/envs/carlos/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel==6.29.5->-r ../requirements.txt (line 12)) (4.9.0)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /opt/homebrew/anaconda3/envs/carlos/lib/python3.12/site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel==6.29.5->-r ../requirements.txt (line 12)) (4.3.6)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/homebrew/anaconda3/envs/carlos/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn==0.13.2->-r ../requirements.txt (line 10)) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/homebrew/anaconda3/envs/carlos/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn==0.13.2->-r ../requirements.txt (line 10)) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/homebrew/anaconda3/envs/carlos/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn==0.13.2->-r ../requirements.txt (line 10)) (4.54.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/homebrew/anaconda3/envs/carlos/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn==0.13.2->-r ../requirements.txt (line 10)) (1.4.7)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/homebrew/anaconda3/envs/carlos/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn==0.13.2->-r ../requirements.txt (line 10)) (3.2.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/homebrew/anaconda3/envs/carlos/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas==2.2.3->-r ../requirements.txt (line 1)) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/homebrew/anaconda3/envs/carlos/lib/python3.12/site-packages (from requests->transformers==4.45.2->-r ../requirements.txt (line 6)) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/homebrew/anaconda3/envs/carlos/lib/python3.12/site-packages (from requests->transformers==4.45.2->-r ../requirements.txt (line 6)) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/homebrew/anaconda3/envs/carlos/lib/python3.12/site-packages (from requests->transformers==4.45.2->-r ../requirements.txt (line 6)) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/homebrew/anaconda3/envs/carlos/lib/python3.12/site-packages (from requests->transformers==4.45.2->-r ../requirements.txt (line 6)) (2024.8.30)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/homebrew/anaconda3/envs/carlos/lib/python3.12/site-packages (from jinja2->torch==2.5.0->-r ../requirements.txt (line 7)) (3.0.2)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /opt/homebrew/anaconda3/envs/carlos/lib/python3.12/site-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel==6.29.5->-r ../requirements.txt (line 12)) (0.8.4)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/homebrew/anaconda3/envs/carlos/lib/python3.12/site-packages (from pexpect>4.3->ipython>=7.23.1->ipykernel==6.29.5->-r ../requirements.txt (line 12)) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /opt/homebrew/anaconda3/envs/carlos/lib/python3.12/site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=7.23.1->ipykernel==6.29.5->-r ../requirements.txt (line 12)) (0.2.13)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/homebrew/anaconda3/envs/carlos/lib/python3.12/site-packages (from yarl<2.0,>=1.12.0->aiohttp->datasets==3.0.1->-r ../requirements.txt (line 9)) (0.2.0)\n",
      "Requirement already satisfied: executing>=1.2.0 in /opt/homebrew/anaconda3/envs/carlos/lib/python3.12/site-packages (from stack-data->ipython>=7.23.1->ipykernel==6.29.5->-r ../requirements.txt (line 12)) (2.1.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /opt/homebrew/anaconda3/envs/carlos/lib/python3.12/site-packages (from stack-data->ipython>=7.23.1->ipykernel==6.29.5->-r ../requirements.txt (line 12)) (2.4.1)\n",
      "Requirement already satisfied: pure-eval in /opt/homebrew/anaconda3/envs/carlos/lib/python3.12/site-packages (from stack-data->ipython>=7.23.1->ipykernel==6.29.5->-r ../requirements.txt (line 12)) (0.2.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LOADING AND PREPROCESSING DATA + ANALYTICS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import transformers, torch\n",
    "\n",
    "\"\"\"\n",
    "Remove uneecessay new lines\n",
    "remove duplicates within one cell\n",
    "Remove links?\n",
    "use keywords to make sure that correct classification is done\n",
    "make validation set more class balanced, i.e. equal num of examples for each category\n",
    "\"\"\"\n",
    "# use keras instead of huggung face to make it easier to work with messing with layers\n",
    "# keep latest entries only in original clean data\n",
    "# double or triple (for some biases) rows that have social, gender, or subjective bias\n",
    "# remove entries greater than 512 words to remove noise\n",
    "# enchance data by repeating key terms\n",
    "# cut 512 from middle of the dataset\n",
    "# try giving it only the labels with 5 word context\n",
    "# try doing subtext technique to give it 1000 words\n",
    "\n",
    "# load data and rename TextEntry column\n",
    "df = pd.read_csv(\"../carlos_data/sentences_preprocessed_data.csv\", encoding=\"utf-8\")\n",
    "df = df.rename(columns={\"TextEntry\":\"Description\"})\n",
    "df.drop(columns=['Subjective Label', 'Gender Label', 'Jargon Label', 'Social Label'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['Description', 'Subjective', 'Gender', 'Jargon', 'Social'],\n",
      "        num_rows: 65030\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['Description', 'Subjective', 'Gender', 'Jargon', 'Social'],\n",
      "        num_rows: 8129\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['Description', 'Subjective', 'Gender', 'Jargon', 'Social'],\n",
      "        num_rows: 8129\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import transformers, torch\n",
    "\n",
    "df = df.dropna(subset=[\"Description\"])\n",
    "\n",
    "# convert data to dictionary\n",
    "data = df.to_dict(\"records\")\n",
    "# Split the data into train and validation and test sets\n",
    "from sklearn.model_selection import train_test_split \n",
    "train_dict, test_dict = train_test_split(data, test_size=0.20, random_state=42) # specifying this random state allows for consistent train, val, and test sets\n",
    "test_dict, validation_dict = train_test_split(test_dict, test_size=0.50, random_state=42)\n",
    "\n",
    "# Create Dataset objects\n",
    "from datasets import Dataset\n",
    "train_dataset = Dataset.from_list(train_dict)\n",
    "\n",
    "test_dataset = Dataset.from_list(test_dict)\n",
    "validation_dataset = Dataset.from_list(validation_dict)\n",
    "\n",
    "# Create DatasetDict\n",
    "from datasets import DatasetDict\n",
    "dataset = DatasetDict({\n",
    "\t\"train\": train_dataset,\n",
    "\t\"test\": test_dataset,\n",
    "\t\"validation\": validation_dataset\n",
    "})\n",
    "\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "train_texts, test_texts, train_labels, test_labels = train_test_split(\n",
    "    df[\"Description\"], df[\"Social\"], test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "text_lengths = [len(t.split()) for t in train_texts]\n",
    "ax = sns.histplot(data=text_lengths, kde=True, stat=\"density\")\n",
    "ax.set_title(\"Distribution of Description lengths (number of words)\")\n",
    "ax.set_xlabel(\"Number of Words\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ENCODING AND TOKENIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# credit: https://github.com/NielsRogge/Transformers-Tutorials\n",
    "labels = [label for label in dataset[\"train\"].features.keys() if label not in [\"ObjectID\", \"Description\"]]\n",
    "id2label = {idx:label for idx, label in enumerate(labels)}\n",
    "label2id = {label:idx for idx, label in enumerate(labels)}\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "import numpy as np\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# credit: https://github.com/NielsRogge/Transformers-Tutorials\n",
    "def preprocess_data(data):\n",
    "\n",
    "\t# save the given batch of descs\n",
    "\tdescs = data[\"Description\"]\n",
    "\n",
    "\t# encode them using bert tokenizer\n",
    "\tencoding = tokenizer(descs, padding=True, truncation=True, max_length=512)#.to(\"mps\")\n",
    "\n",
    "\t# create numpy array (no need to convert T/F to 0/1 since we annotated that way)\n",
    "\t# MATRIX FORMAT:\n",
    "\t# |---------------------------------\n",
    "\t# | bias   | bias1 bias2 bias3 bias4\n",
    "\t# |--------+------------------------\n",
    "\t# | desc0  |   1     0     1     0\n",
    "\t# | desc1  |   0     1     0     1\n",
    "\t# | desc2  |   0     1     0     0\n",
    "\t# | ...    |  ...   ...   ...   ...\n",
    "\t# \n",
    "\t# Convert integers to float and data to an NDarray\n",
    "\tsubjective = np.array(data[\"Subjective\"], dtype=float)\n",
    "\tgender = np.array(data[\"Gender\"], dtype=float)\n",
    "\tjargon = np.array(data[\"Jargon\"], dtype=float)\n",
    "\tsocial = np.array(data[\"Social\"], dtype=float)\n",
    "\t# Stack the arrays column-wise to form a 2D array (matrix)\n",
    "\tlabels_matrix = np.stack((subjective, gender, jargon, social), axis=1)\n",
    "\n",
    "\t\n",
    "\t# # Credit ChatGPT\n",
    "\t# # Validate the data stacking by comparing 3 random indices\n",
    "\t# import random\n",
    "\t# for _ in range(3):\n",
    "\t# \tidx = random.randint(0, len(subjective) - 1)\n",
    "\t# \tdataset_labels = [data[\"Subjective\"][idx], data[\"Gender\"][idx], data[\"Jargon\"][idx], data[\"Social\"][idx]]\n",
    "\t# \tmatrix_labels = labels_matrix[idx].tolist()\n",
    "\t# \tassert dataset_labels == matrix_labels, f\"Mismatch at index {idx}: {dataset_labels} != {matrix_labels}\"\n",
    "\t# \tprint(f\"Index {idx} matches: {dataset_labels}\")\n",
    "\n",
    "\n",
    "\t# FORMAT OF var encoding of type BatchEncoding (the length of the vals of each key \n",
    "\t# equal the num of descs/objects in given batch):\n",
    "\t# input_ids: [101, 1030, 4748, 7229, 1035, ...], ... (tokens/key/id for each BERT word)\n",
    "\t# token_type_ids: [0, 0, 0, 0, 0, ...], ... (defines the type of each token; we only have all zeros)\n",
    "\t# attention_mask: [1, 1, 1, 1, 1, ...], ... (tells model what to focus on by marking 1 for all tokens other than padding)\n",
    "\t# labels: [1.0, 1.0, 0.0, 0.0], ... (labels corresponding to the tokens)\n",
    "\tencoding[\"labels\"] = labels_matrix.tolist()\n",
    "\n",
    "\treturn encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_dataset = dataset.map(preprocess_data, batched=True, remove_columns=dataset['train'].column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see example\n",
    "print(tokenizer.decode(encoded_dataset[\"train\"][6][\"input_ids\"]))\n",
    "print(encoded_dataset[\"train\"][6][\"labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make dataset a standard torch dataset by converting to tensors\n",
    "encoded_dataset.set_format(\"torch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LOADING MODEL + TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertForSequenceClassification\n",
    "\n",
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", \n",
    "                                                           problem_type=\"multi_label_classification\", \n",
    "                                                           num_labels=len(labels),\n",
    "                                                           id2label=id2label,\n",
    "                                                           label2id=label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Add Warmup?\n",
    "Experiment with learning rate\n",
    "experiment with batch size\n",
    "experient with gradient_accumulation_steps\n",
    "another metric?\n",
    "Choose another optimizer: RMSprop, SGD...\n",
    "Increase the learning rate by default and then use the callback ReduceLROnPlateau\n",
    "\"\"\"\n",
    "# use keras instead of huggung face to make it easier to work with messing with layers\n",
    "# remove entries greater than 512 words to remove noise\n",
    "# enchance data by repeatung key terms\n",
    "# cut 512 from middle of the dataset\n",
    "# try giving it only the labels with 5 word context\n",
    "# try doing subtext technique to give it 1000 words\n",
    "\n",
    "\n",
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "num_epochs = 20\n",
    "batch_size = 64\n",
    "lr = 2e-5\n",
    "metric_name = \"f1\"\n",
    "decay = 0.01\n",
    "\n",
    "model_path = \"./model\"\n",
    "tokenizer_path = \"./tokenizer\"\n",
    "logs_path = \"./logs\"\n",
    "\n",
    "# with open('hg_token.txt', 'r') as file:\n",
    "# \thg_token = file.read()\n",
    "hg_token = \"\"\n",
    "\n",
    "\n",
    "# args for training the model\n",
    "# save the model every epoch and choose the best performing epoch as the final version of the model\n",
    "args = TrainingArguments(\n",
    "\teval_strategy = \"epoch\",\n",
    "\tsave_strategy = \"epoch\",\n",
    "    # save_total_limit = 5,\n",
    "\tlogging_strategy = \"epoch\",\n",
    "\tlearning_rate = lr,\n",
    "\tper_device_train_batch_size = batch_size,\n",
    "\tper_device_eval_batch_size = batch_size,\n",
    "\tnum_train_epochs = num_epochs,\n",
    "\tweight_decay = decay,\n",
    "\tload_best_model_at_end = True,\n",
    "\tmetric_for_best_model = metric_name,\n",
    "\tlogging_dir = logs_path,\n",
    "\toutput_dir = model_path,\n",
    "    warmup_steps=100,\n",
    "\t# use_mps_device = True,\n",
    "\t# use_cpu = False,\n",
    "\tlogging_steps = 1,\n",
    "\t# gradient_accumulation_steps=2,\n",
    "\t\n",
    "\t# hub_token = hg_token,\n",
    "\t# hub_model_id = \"raasikhk/carlos_bert_v2_2\",\n",
    "\t# push_to_hub=True,\n",
    "\treport_to=\"tensorboard\"\n",
    ")\n",
    "\n",
    "import os\n",
    "from sklearn.metrics import f1_score, roc_auc_score, accuracy_score, confusion_matrix\n",
    "from transformers import EvalPrediction\n",
    "import torch\n",
    "from numpy import ndarray\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Tuple\n",
    "\n",
    "def get_next_image_number(directory: str) -> int:\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "        return 1\n",
    "    images = glob.glob(os.path.join(directory, '*.png'))\n",
    "    if not images:\n",
    "        return 1\n",
    "    numbers = [int(os.path.basename(image).split('_')[0]) for image in images]\n",
    "    return max(numbers) + 1\n",
    "\n",
    "def plot_confusion_matrix(cm, save_path, title):\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(cm))\n",
    "    plt.xticks(tick_marks, tick_marks, rotation=45)\n",
    "    plt.yticks(tick_marks, tick_marks)\n",
    "    \n",
    "    for i in range(len(cm)):\n",
    "        for j in range(len(cm[i])):\n",
    "            plt.text(j, i, format(cm[i, j], 'd'), horizontalalignment=\"center\", color=\"white\" if cm[i, j] > cm.max() / 2. else \"black\")\n",
    "    \n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path)\n",
    "    plt.close()\n",
    "\n",
    "def my_accuracy_score(y_true: np.ndarray, y_pred: np.ndarray) -> Tuple[int, int, int, int]:\n",
    "    directory = 'cm'\n",
    "    image_number = get_next_image_number(directory)\n",
    "    \n",
    "    labels = [\"Subjective\", \"Gender\", \"Jargon\", \"Social\"]\n",
    "    true_pos_list, false_pos_list, true_neg_list, false_neg_list = [], [], [], []\n",
    "\n",
    "    for i, label in enumerate(labels):\n",
    "        save_path = os.path.join(directory, f'{image_number}_{label}.png')\n",
    "        \n",
    "        # Calculate confusion matrix for the current label\n",
    "        cm = confusion_matrix(y_true[:, i], y_pred[:, i])\n",
    "        \n",
    "        # Plot confusion matrix\n",
    "        plot_confusion_matrix(cm, save_path, f'Confusion Matrix - {label}')\n",
    "        \n",
    "        # Calculate true positives, false positives, true negatives, false negatives\n",
    "        true_pos = np.sum((y_true[:, i] == 1) & (y_pred[:, i] == 1))\n",
    "        false_pos = np.sum((y_true[:, i] == 0) & (y_pred[:, i] == 1))\n",
    "        true_neg = np.sum((y_true[:, i] == 0) & (y_pred[:, i] == 0))\n",
    "        false_neg = np.sum((y_true[:, i] == 1) & (y_pred[:, i] == 0))\n",
    "        \n",
    "        true_pos_list.append(true_pos)\n",
    "        false_pos_list.append(false_pos)\n",
    "        true_neg_list.append(true_neg)\n",
    "        false_neg_list.append(false_neg)\n",
    "    \n",
    "    return (\n",
    "        sum(true_pos_list), sum(false_pos_list), \n",
    "        sum(true_neg_list), sum(false_neg_list)\n",
    "    )\n",
    "\n",
    "\n",
    "def partial_accuracy_score(y_true: ndarray, y_pred: ndarray):\n",
    "\tnum_objects = len(y_true)\n",
    "\tnum_labels = len(y_true)*4\n",
    "\tcorrect_predictions = 0\n",
    "\t\n",
    "\tfor i in range(num_objects):\n",
    "\t\tfor j in range(len(y_true[i])):\n",
    "\t\t\tif y_true[i][j] == y_pred[i][j]:\n",
    "\t\t\t\tcorrect_predictions += 1\n",
    "\t\n",
    "\taccuracy = correct_predictions / num_labels\n",
    "\treturn accuracy\n",
    "\n",
    "# source: https://jesusleal.io/2021/04/21/Longformer-multilabel-classification/\n",
    "def multi_label_metrics(predictions, labels, threshold=0.5):\n",
    "\t# first, apply sigmoid on predictions which are of shape (batch_size, num_labels)\n",
    "\tsigmoid = torch.nn.Sigmoid()\n",
    "\tprobs = sigmoid(torch.Tensor(predictions))\n",
    "\t# next, use threshold to turn them into integer predictions\n",
    "\ty_pred = np.zeros(probs.shape)\n",
    "\ty_pred[np.where(probs >= threshold)] = 1\n",
    "\t# finally, compute metrics\n",
    "\ty_true = labels\n",
    "\tf1_micro_average = f1_score(y_true=y_true, y_pred=y_pred, average='micro')\n",
    "\troc_auc = roc_auc_score(y_true, y_pred, average = 'micro')\n",
    "\taccuracy = accuracy_score(y_true, y_pred)\n",
    "\tmyacc = partial_accuracy_score(y_true, y_pred)\n",
    "\ttrue_pos, false_pos, true_neg, false_neg = my_accuracy_score(y_true, y_pred)\n",
    "\t# return as dictionary\n",
    "\tmetrics = {'f1': f1_micro_average,\n",
    "\t\t\t\t'roc_auc': roc_auc,\n",
    "\t\t\t\t'exact_match_acc': accuracy,\n",
    "\t\t\t\t\"partial_acc\": myacc,\n",
    "\t\t\t\t'true_pos': true_pos,\n",
    "        \t\t'true_neg': true_neg,\n",
    "        \t\t'false_neg': false_neg,\n",
    "\t\t\t\t'false_pos': false_pos}\n",
    "\treturn metrics\n",
    "\n",
    "def compute_metrics(p: EvalPrediction):\n",
    "\tpreds = p.predictions[0] if isinstance(p.predictions, \n",
    "\t\t\ttuple) else p.predictions\n",
    "\tresult = multi_label_metrics(\n",
    "\t\tpredictions=preds, \n",
    "\t\tlabels=p.label_ids)\n",
    "\treturn result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "\tmodel,\n",
    "\targs,\n",
    "\ttrain_dataset=encoded_dataset[\"train\"],\n",
    "\teval_dataset=encoded_dataset[\"validation\"],\n",
    "\ttokenizer=tokenizer,\n",
    "\tcompute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TrainOutput(global_step=5430, training_loss=0.039493819055855826, metrics={'train_runtime': 1080.8201, 'train_samples_per_second': 40.081, 'train_steps_per_second': 5.024, 'total_flos': 1.139817559375872e+16, 'train_loss': 0.039493819055855826, 'epoch': 30.0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{'eval_loss': 0.2363041341304779,\n",
    " 'eval_f1': 0.8076923076923078,\n",
    " 'eval_roc_auc': 0.8846526655896608,\n",
    " 'eval_exact_match_acc': 0.8232044198895028,\n",
    " 'eval_partial_acc': 0.9447513812154696,\n",
    " 'eval_true_pos': 84,\n",
    " 'eval_true_neg': 600,\n",
    " 'eval_false_neg': 21,\n",
    " 'eval_false_pos': 19,\n",
    " 'eval_runtime': 2.0471,\n",
    " 'eval_samples_per_second': 88.418,\n",
    " 'eval_steps_per_second': 11.235,\n",
    " 'epoch': 30.0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view logs (only needed for analysis)\n",
    "# !pip install tensorboard\n",
    "!tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save_pretrained(\"model\")\n",
    "# tokenizer.save_pretrained(\"tokenizer\")\n",
    "# tokenizer = transformers.BertTokenizer.from_pretrained(\"tokenizer\")\n",
    "# model = transformers.BertForSequenceClassification.from_pretrained(\"model/checkpoint-1200\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TESTING NEWLY TRAINED MODEL BY HAND"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test a description\n",
    "text = \"December 1992 lead-in term added. January 1991 alternate term added. Object fumigated in Orkin's Piedmont vault with Vikane in 1994\"\n",
    "\n",
    "encoding = tokenizer(text, return_tensors=\"pt\")\n",
    "encoding = {k: v.to(trainer.model.device) for k,v in encoding.items()}\n",
    "print(f\"encoding: {encoding}\")\n",
    "\n",
    "outputs = trainer.model(**encoding)\n",
    "# print(f\"outputs: {outputs}\")\n",
    "\n",
    "logits = outputs.logits\n",
    "print(f\"logits: {logits}\")\n",
    "\n",
    "# apply sigmoid + threshold\n",
    "sigmoid = torch.nn.Sigmoid()\n",
    "probs = sigmoid(logits.squeeze().cpu())\n",
    "print(f\"probs: {probs}\")\n",
    "predictions = np.zeros(probs.shape)\n",
    "predictions[np.where(probs >= 0.5)] = 1\n",
    "# turn predicted id's into actual label names\n",
    "predicted_labels = [id2label[idx] for idx, label in enumerate(predictions) if label == 1.0]\n",
    "print(predicted_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------------------------------------------------\n",
    "-----------------------------------------------------------------------------\n",
    "-----------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LOADING MODEL FROM HUGGINGFACE AND TESTING "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "only run this block below if you have not just trained the model here and would like to load our finetuned version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST THE MODEL\n",
    "# IF YOU DONT WANT TO TRAIN THEN LOAD MODEL FROM HUGGINGFACE\n",
    "\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TextClassificationPipeline\n",
    "import torch\n",
    "\n",
    "device = 0 if torch.cuda.is_available() else -1\n",
    "\n",
    "# if tokenizer == None:\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"raasikhk/carlos_bert_v2_2\", revision=\"4f6590dd149a1cf31d0cc09fa6e2db13fdfc15f1\")\n",
    "# if model == None:\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"raasikhk/carlos_bert_v2_2\", revision=\"4f6590dd149a1cf31d0cc09fa6e2db13fdfc15f1\", output_attentions=True)\n",
    "\n",
    "pipe = TextClassificationPipeline(model=model, tokenizer=tokenizer, top_k=None, truncation=True, padding=True, device=device)\n",
    "\n",
    "\"\"\"Sinker\n",
    "\n",
    "NOTE: UPDATED in June 2021 with information from 1984 accession worksheet.\n",
    "\n",
    "A February 14, 1997 file memo from registrar Lori Iliff discussed how sources and provenance were determined for objects that were believed to have an Etowah or Etowah-related provenance.  This memo did not discuss the X.0600-X.0697 numbered objects, as the sources and provenance of those objects had been discussed in a March 1990 memo.  Information regarding the objects in the 1997 memo came from the Accession Log I (green-blue colored ledger) and old accession sheets. According to Lori's memo it was unclear when the accession log was started, but it was on or prior to 1984.  The accession worksheets had been created in 1984.\n",
    "\n",
    "According to Lori's memo, the designation of Etowah as provenance and Phillips Academy as source on the accession worksheets seemed arbitrary and not based on prior museum records.  Therefore the designation of Etowah or Phillips Academy based solely on an accession worksheet may be suspect. Below is a summary of what was found for this object.\n",
    "\n",
    "X.0232.024 - According to the memo, the accession log lists no source, but lists Etowah as provenance.  The memo does not mention an accession worksheet. There is a 1984 accession worksheet in the object file.  It notes the provenance as Georgia, Etowah Mounds and does not note a source.\n",
    "\n",
    "The memos from the 1990s do not mention the \"Specimen Record\" worksheets housed in the blue fabric-covered binders. A few of these worksheets contain notes added by Lori Iliff in 1994.  It is unclear why these worksheets are not mentioned in the 1990s memos, but for completeness, their information is noted here.  It is however, unclear when these worksheets were created, by whom, and where the information in the worksheets came from.  Many have notes regarding packing objects for storage in 1982, so it can be assumed these were created in 1982 or earlier. There is one Specimen Record for X.0232.023, X.0232.024, X.0280.001, X.0280.002, X.0281 and X.0282.  The Specimen Record does not list a provenance, and W.H. Ferguson is listed as the source.\n",
    "\n",
    "The catalog for the 1982 \"A Preview of the Collections\"exhibition in Schatten Gallery lists the credit line for X.0232.024 as \"Gift of W.H. Ferguson\", but there is no indication as to where this information came from.\n",
    "\n",
    ".\n",
    "\n",
    "Luminescence induced by the absorption of infrared radiation, visible light, or ultraviolet radiation.  RHDEL2.\n",
    "\n",
    "Identified as Jasper by William Size.\"\"\"\n",
    "\n",
    "\n",
    "texts = [\"\"\"A Chewa boy in Malawi must undergo a three-day initiation in order to achieve full status as an adult. Masks, such as this one, may be commissioned from a recognized carver by a friend or relative, or by the initiate himself... The mischievous characters interact with and perform for the audience to teach moral lessons and enforce social norms. This extraordinary example is carved from a dense, oily hardwood and sparingly decorated with red European paint. Its commanding presence is marked by a strong brow, varying textures and materials in the beard, and a rather wild full head of hair.\"\"\"]\n",
    "\n",
    "# Make predictions\n",
    "predictions = pipe(texts)\n",
    "\n",
    "# Print the predictions\n",
    "for i, text in enumerate(texts):\n",
    "    # print(f\"Text: {text}\")\n",
    "    print(f\"Predictions: {predictions[i]}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CALCULATING ACCURACY AND OTHER METRICS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make progressbar\n",
    "import sys\n",
    "def print_progress_bar(percentage):\n",
    "    bar_length = 40 \n",
    "    block = int(bar_length * (percentage / 100))\n",
    "    progress_bar = \"█\" * block + \" \" * (bar_length - block)\n",
    "    sys.stdout.write(f\"\\r[{progress_bar}] {percentage:.2f}%\")\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CALCULATE ACCURACY\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TextClassificationPipeline\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "unclean = False # test on filtered descriptions or original, noisy ones\n",
    "\n",
    "test_on = \"validation\" # choose what to test on\n",
    "test_on = \"test\"\n",
    "\n",
    "print(\"OPTIONS:\")\n",
    "print(f\"unclean data = {unclean}\")\n",
    "print(f\"testing set = {test_on}\\n\")\n",
    "\n",
    "device = 0 if torch.cuda.is_available() else -1\n",
    "\n",
    "# model = AutoModelForSequenceClassification.from_pretrained(\"raasikhk/carlos_bert_v2_2\")\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"raasikhk/carlos_bert_v2_2\")\n",
    "\n",
    "pipe = TextClassificationPipeline(model=model, tokenizer=tokenizer, top_k=None, truncation=True, padding=True, device=device)\n",
    "\n",
    "print(\"Getting data...\")\n",
    "if unclean:\n",
    "\tunclean_df = pd.read_excel(\"../../../carlos_data/preprocessed_data_v3.xlsx\")\n",
    "\tunclean_df = unclean_df.drop(['Social', 'Jargon', 'Subjective', 'Gender'], axis=1)\n",
    "\n",
    "\t# Replace with test dataset\n",
    "\ttest_split = dataset[test_on]\n",
    "\ttest_split = pd.DataFrame(test_split)\n",
    "\ttest_split = test_split.drop(['Social', 'Jargon', 'Subjective', 'Gender'], axis=1)\n",
    "\n",
    "\t# Merge test_descriptions with unclean_df on ObjectID\n",
    "\tmerged_df = test_split.merge(unclean_df, on=\"ObjectID\", suffixes=('', '_unclean'), how='left')\n",
    "\t# Extract the newly replaced descriptions\n",
    "\tnew_descriptions = merged_df[\"TextEntry\"].values\n",
    "\n",
    "\t# Get list of unclean descriptions\n",
    "\ttest_descriptions = new_descriptions.tolist()\n",
    "else:\n",
    "    test_descriptions = dataset[test_on][\"Description\"]\n",
    "\n",
    "# make predictions variable of the format\n",
    "# -----------------------\n",
    "# bias1 bias2 bias3 bias4\n",
    "# -----------------------\n",
    "#  1     0     1     0\n",
    "#  0     1     0     1\n",
    "#  0     1     0     0\n",
    "# ...   ...   ...   ...\n",
    "predictions = np.zeros((len(test_descriptions), 4), int)\n",
    "\n",
    "print(\"Getting predictions...\")\n",
    "c = 0 # counter for progress bar\n",
    "for i in range(len(test_descriptions)):\n",
    "    pred = pipe(test_descriptions[i])\n",
    "    for j in range(4):\n",
    "        label = pred[0][j][\"label\"]\n",
    "        score = pred[0][j][\"score\"]\n",
    "        if label == \"Subjective\":\n",
    "            predictions[i][0] = 1 if score >= 0.5 else 0\n",
    "        elif label == \"Gender\":\n",
    "            predictions[i][1] = 1 if score >= 0.5 else 0\n",
    "        elif label == \"Jargon\":\n",
    "            predictions[i][2] = 1 if score >= 0.5 else 0\n",
    "        elif label == \"Social\":\n",
    "            predictions[i][3] = 1 if score >= 0.5 else 0\n",
    "    c += 1\n",
    "    print_progress_bar(c/len(test_descriptions)*100)\n",
    "\n",
    "# merge classifications of each bias column wise to create matrix:\n",
    "# subj0   gend0   jarg0   soci0\n",
    "# subj0   gend0   jarg0   soci0\n",
    "# subj0   gend0   jarg0   soci0\n",
    "true_values = np.column_stack((dataset[test_on][\"Subjective\"], dataset[test_on][\"Gender\"], \n",
    "                               dataset[test_on][\"Jargon\"], dataset[test_on][\"Social\"]))\n",
    "\n",
    "print(\"\\n\\nAccuracy Calculations:\")\n",
    "# Use Scikit-learn method\n",
    "print(f\"Accuracy: {accuracy_score(true_values, predictions)}\")\n",
    "\n",
    "# Calculate partial accuracy\n",
    "part_acc_score = 0\n",
    "total = true_values.size  # Or predictions.size, since both have the same shape\n",
    "\n",
    "for i in range(true_values.shape[0]):\n",
    "    for j in range(true_values.shape[1]):\n",
    "        if true_values[i][j] == predictions[i][j]:\n",
    "            part_acc_score += 1\n",
    "\n",
    "print(f\"Partial Accuracy: {part_acc_score/total}\")\n",
    "print(f\"F1 Score: {f1_score(true_values, predictions, average='micro')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get accuracy per label\n",
    "import numpy as np\n",
    "\n",
    "def calculate_accuracy_per_label(predictions, true_values):\n",
    "    accuracies = {}\n",
    "    labels = [\"Subjective\", \"Gender\", \"Jargon\", \"Social\"]\n",
    "    \n",
    "    for i, label in enumerate(labels):\n",
    "        correct_predictions = np.sum(predictions[:, i] == true_values[:, i])\n",
    "        total_predictions = predictions.shape[0]\n",
    "        accuracy = correct_predictions / total_predictions\n",
    "        accuracies[label] = accuracy\n",
    "\n",
    "    return accuracies\n",
    "\n",
    "# Example usage\n",
    "accuracies = calculate_accuracy_per_label(predictions, true_values)\n",
    "print(accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save predictions for validation or test set (depending on choice above) as csv\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(predictions, columns=[\"Subjective\", \"Gender\", \"Jargon\", \"Social\"])\n",
    "\n",
    "# Add the descriptions as the first column (choose unclean in block above)\n",
    "if unclean:\n",
    "\tdf.insert(0, \"Description\", test_descriptions)\n",
    "else:\n",
    "\tdf.insert(0, \"FilteredDescription\", test_descriptions)\n",
    "\n",
    "# add objectID\n",
    "df.insert(0, \"ObjectID\", dataset[test_on][\"ObjectID\"])\n",
    "\n",
    "df.to_csv(f\"carlos_data/bert_{test_on}_predictions.csv\", index=False, encoding=\"utf-8\")\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BELOW IS RANDOM EXPERIMENTAL CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize list to store confusion matrices for each label\n",
    "confusion_matrices = []\n",
    "\n",
    "# Iterate over each label (column in the matrices)\n",
    "for i in range(true_values.shape[1]):\n",
    "    # Compute confusion matrix for the current label\n",
    "    cm = confusion_matrix(true_values[:, i], predictions[:, i])\n",
    "    confusion_matrices.append(cm)\n",
    "\n",
    "# Print confusion matrices for each label\n",
    "for i, cm in enumerate(confusion_matrices):\n",
    "    print(f\"Confusion Matrix for Label {i}:\")\n",
    "    print(cm)\n",
    "    print()\n",
    "\n",
    "    # Optional: Plot the confusion matrix\n",
    "    plt.figure(figsize=(5, 4))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title(f'Confusion Matrix for Label {i}')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load pre-trained model and tokenizer\n",
    "\n",
    "# Example text\n",
    "text = \"The quick brown fox jumps over the lazy dog\"\n",
    "\n",
    "# Tokenize and prepare input\n",
    "inputs = tokenizer(text, return_tensors='pt')\n",
    "input_ids = inputs['input_ids']\n",
    "attention_mask = inputs['attention_mask']\n",
    "\n",
    "# Forward pass with attention output\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "attentions = outputs.attentions  # List of attention scores for each layer\n",
    "\n",
    "# Function to visualize attention for the last layer\n",
    "def visualize_attention(attentions, input_ids, tokenizer, layer_idx=-1):\n",
    "    attention = attentions[layer_idx].squeeze().detach().numpy()  # Get attention scores for the specified layer\n",
    "    # Token mapping\n",
    "    tokens = tokenizer.convert_ids_to_tokens(input_ids.squeeze().tolist())\n",
    "    \n",
    "    # Plot attention for the first attention head in the layer\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    sns.heatmap(attention[0], xticklabels=tokens, yticklabels=tokens, cmap='viridis')\n",
    "    plt.title(f'Attention Map - Layer {layer_idx + 1}')\n",
    "    plt.xlabel('Token')\n",
    "    plt.ylabel('Token')\n",
    "    plt.show()\n",
    "\n",
    "# Visualize attention for the last layer\n",
    "visualize_attention(attentions, input_ids, tokenizer, layer_idx=-1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "carlos",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
