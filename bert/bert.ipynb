{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Version 2.2 concatenates all texts by only keeping sentences where bias is present. This needs a new preprocessing script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pandas transformers torch datasets numpy openpyxl scikit-learn\n",
    "# !pip install accelerate -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import transformers, torch\n",
    "\n",
    "\"\"\"\n",
    "Remove uneecessay new lines\n",
    "remove duplicates within one cell\n",
    "Remove links?\n",
    "use keywords to make sure that correct classification is done\n",
    "make validation set more class balanced, i.e. equal num of examples for each category\n",
    "\"\"\"\n",
    "# use keras instead of huggung face to make it easier to work with messing with layers\n",
    "# keep latest entries only in original clean data\n",
    "# double or triple (for some biases) rows that have social, gender, or subjective bias\n",
    "# remove entries greater than 512 words to remove noise\n",
    "# enchance data by repeating key terms\n",
    "# cut 512 from middle of the dataset\n",
    "# try giving it only the labels with 5 word context\n",
    "# try doing subtext technique to give it 1000 words\n",
    "\n",
    "# load data and rename TextEntry column\n",
    "df = pd.read_excel(\"../carlos_data/preprocessed_data.xlsx\")\n",
    "df = df.rename(columns={\"TextEntry\":\"Description\"})\n",
    "df.drop(columns=['Subjective Label', 'Gender Label', 'Jargon Label', 'Social Label'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['ObjectID', 'Description', 'Subjective', 'Gender', 'Jargon', 'Social'],\n",
      "        num_rows: 1444\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['ObjectID', 'Description', 'Subjective', 'Gender', 'Jargon', 'Social'],\n",
      "        num_rows: 180\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['ObjectID', 'Description', 'Subjective', 'Gender', 'Jargon', 'Social'],\n",
      "        num_rows: 181\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import transformers, torch\n",
    "\n",
    "# convert data to dictionary\n",
    "data = df.to_dict(\"records\")\n",
    "# Split the data into train and validation and test sets\n",
    "from sklearn.model_selection import train_test_split \n",
    "train_dict, test_dict = train_test_split(data, test_size=0.20, random_state=42) # specifying this random state allows for consistent train, val, and test sets\n",
    "test_dict, validation_dict = train_test_split(test_dict, test_size=0.50, random_state=42) # same here\n",
    "\n",
    "# Create Dataset objects\n",
    "from datasets import Dataset\n",
    "train_dataset = Dataset.from_list(train_dict)\n",
    "test_dataset = Dataset.from_list(test_dict)\n",
    "validation_dataset = Dataset.from_list(validation_dict)\n",
    "\n",
    "# Create DatasetDict\n",
    "from datasets import DatasetDict\n",
    "dataset = DatasetDict({\n",
    "\t\"train\": train_dataset,\n",
    "\t\"test\": test_dataset,\n",
    "\t\"validation\": validation_dataset\n",
    "})\n",
    "\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save annotated data for graphs and gpt testing/training\n",
    "train_df = pd.DataFrame(train_dict)\n",
    "test_df = pd.DataFrame(test_dict)\n",
    "validation_df = pd.DataFrame(validation_dict)\n",
    "\n",
    "train_df.to_csv(\"../../../carlos_data/model_data/bert_v2_2_train_data.csv\", index=False)\n",
    "validation_df.to_csv(\"../../../carlos_data/model_data/bert_v2_2_validation_data.csv\", index=False)\n",
    "test_df.to_csv(\"../../../carlos_data/model_data/bert_v2_2_test_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Number of Words')"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "train_texts, test_texts, train_labels, test_labels = train_test_split(\n",
    "    df[\"Description\"], df[\"Social\"], test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "text_lengths = [len(t.split()) for t in train_texts]\n",
    "ax = sns.histplot(data=text_lengths, kde=True, stat=\"density\")\n",
    "ax.set_title(\"Distribution of Description lengths (number of words)\")\n",
    "ax.set_xlabel(\"Number of Words\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Subjective', 'Gender', 'Jargon', 'Social']"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# credit: https://github.com/NielsRogge/Transformers-Tutorials\n",
    "labels = [label for label in dataset[\"train\"].features.keys() if label not in [\"ObjectID\", \"Description\"]]\n",
    "id2label = {idx:label for idx, label in enumerate(labels)}\n",
    "label2id = {label:idx for idx, label in enumerate(labels)}\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "import numpy as np\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# credit: https://github.com/NielsRogge/Transformers-Tutorials\n",
    "def preprocess_data(data):\n",
    "\n",
    "\t# save the given batch of descs\n",
    "\tdescs = data[\"Description\"]\n",
    "\n",
    "\t# encode them using bert tokenizer\n",
    "\tencoding = tokenizer(descs, padding=True, truncation=True, max_length=512)#.to(\"mps\")\n",
    "\n",
    "\t# create numpy array (no need to convert T/F to 0/1 since we annotated that way)\n",
    "\t# MATRIX FORMAT:\n",
    "\t# |---------------------------------\n",
    "\t# | bias   | bias1 bias2 bias3 bias4\n",
    "\t# |--------+------------------------\n",
    "\t# | desc0  |   1     0     1     0\n",
    "\t# | desc1  |   0     1     0     1\n",
    "\t# | desc2  |   0     1     0     0\n",
    "\t# | ...    |  ...   ...   ...   ...\n",
    "\t# \n",
    "\t# Convert integers to float and data to an NDarray\n",
    "\tsubjective = np.array(data[\"Subjective\"], dtype=float)\n",
    "\tgender = np.array(data[\"Gender\"], dtype=float)\n",
    "\tjargon = np.array(data[\"Jargon\"], dtype=float)\n",
    "\tsocial = np.array(data[\"Social\"], dtype=float)\n",
    "\t# Stack the arrays column-wise to form a 2D array (matrix)\n",
    "\tlabels_matrix = np.stack((subjective, gender, jargon, social), axis=1)\n",
    "\n",
    "\t\n",
    "\t# # Credit ChatGPT\n",
    "\t# # Validate the data stacking by comparing 3 random indices\n",
    "\t# import random\n",
    "\t# for _ in range(3):\n",
    "\t# \tidx = random.randint(0, len(subjective) - 1)\n",
    "\t# \tdataset_labels = [data[\"Subjective\"][idx], data[\"Gender\"][idx], data[\"Jargon\"][idx], data[\"Social\"][idx]]\n",
    "\t# \tmatrix_labels = labels_matrix[idx].tolist()\n",
    "\t# \tassert dataset_labels == matrix_labels, f\"Mismatch at index {idx}: {dataset_labels} != {matrix_labels}\"\n",
    "\t# \tprint(f\"Index {idx} matches: {dataset_labels}\")\n",
    "\n",
    "\n",
    "\t# FORMAT OF var encoding of type BatchEncoding (the length of the vals of each key \n",
    "\t# equal the num of descs/objects in given batch):\n",
    "\t# input_ids: [101, 1030, 4748, 7229, 1035, ...], ... (tokens/key/id for each BERT word)\n",
    "\t# token_type_ids: [0, 0, 0, 0, 0, ...], ... (defines the type of each token; we only have all zeros)\n",
    "\t# attention_mask: [1, 1, 1, 1, 1, ...], ... (tells model what to focus on by marking 1 for all tokens other than padding)\n",
    "\t# labels: [1.0, 1.0, 0.0, 0.0], ... (labels corresponding to the tokens)\n",
    "\tencoding[\"labels\"] = labels_matrix.tolist()\n",
    "\n",
    "\treturn encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_dataset = dataset.map(preprocess_data, batched=True, remove_columns=dataset['train'].column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] sprinkler flask provenance taken from purchase document 3 ( see accession lot ). provenance taken from purchase document 3 ( see accession lot ). purchased by georges ricard february 28, 1974 from raynaud and gamet auctions, marseille, lot # 258. expert : laporte. catalogue description : “ flacon d ’ athlete en verre a panse ornee en relief de torsades. rome, ier - iv eme siecles ad. hauteur 10 cms. ” senusret purchase reference no. 3. ex coll. musee de l'egypte et le monde antique, collection sanousrit, monaco, 1975 - 1982. ex coll. georges ricard foundation, santa barbara, california. purchased by georges ricard february 28, 1974 from raynaud and gamet auctions, marseille, lot # 258. expert : laporte. catalogue description : “ flacon d ’ athlete en verre a panse ornee en relief de torsades. rome, ier - iv eme siecles ad. hauteur 10 cms. ” senusret purchase reference no. 3. ex coll. musee de l'egypte et le monde antique, collection sanousrit, monaco, 1975 - 1982. ex coll. georges ricard foundation, santa barbara, california. this glass sprinkler is blown from transparent olive green glass. beneath the perfectly symmetrical horizontal rim, a straight neck meets the body with a constriction and a diaphragm. the subtle spiral ribbing on the spherical body was achieved by pattern blowing. the bottom is flat and smooth with a faint pontil mark. syria, eastern roman empire, late third to early fourth century ad. “ most sprinklers with this type of surface pattern probably date from the late third and early fourth centuries … such sprinklers were made in more than one workshop, but probably not over a long period of time, because relatively few have been preserved … expanded mold - blown ribs created in a one - piece conical mold [ is ] a technique that is not common with sprinklers ” ( stern, 2001 : 153 ). < b > parallel : < / b > “ sprinkler flask. yellow - green glass. this flask made out of a thick glass fabric has a spherical body decorated with swirling horizontal ribs. the tubular neck flares out to a wide horizontal infolded rim. at the [SEP]\n",
      "[0.0, 0.0, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "# see example\n",
    "print(tokenizer.decode(encoded_dataset[\"train\"][0][\"input_ids\"]))\n",
    "print(encoded_dataset[\"train\"][0][\"labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make dataset a standard torch dataset by converting to tensors\n",
    "encoded_dataset.set_format(\"torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertForSequenceClassification\n",
    "\n",
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", \n",
    "                                                           problem_type=\"multi_label_classification\", \n",
    "                                                           num_labels=len(labels),\n",
    "                                                           id2label=id2label,\n",
    "                                                           label2id=label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Add Warmup?\n",
    "Experiment with learning rate\n",
    "experiment with batch size\n",
    "experient with gradient_accumulation_steps\n",
    "another metric?\n",
    "Choose another optimizer: RMSprop, SGD...\n",
    "Increase the learning rate by default and then use the callback ReduceLROnPlateau\n",
    "\"\"\"\n",
    "# use keras instead of huggung face to make it easier to work with messing with layers\n",
    "# remove entries greater than 512 words to remove noise\n",
    "# enchance data by repeatung key terms\n",
    "# cut 512 from middle of the dataset\n",
    "# try giving it only the labels with 5 word context\n",
    "# try doing subtext technique to give it 1000 words\n",
    "\n",
    "\n",
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "num_epochs = 30\n",
    "batch_size = 8\n",
    "lr = 2e-5\n",
    "metric_name = \"f1\"\n",
    "decay = 0.01\n",
    "\n",
    "model_path = \"./model\"\n",
    "tokenizer_path = \"./tokenizer\"\n",
    "logs_path = \"./logs\"\n",
    "\n",
    "with open('../../../hg_token.txt', 'r') as file:\n",
    "\thg_token = file.read()\n",
    "\n",
    "\n",
    "# args for training the model\n",
    "# save the model every epoch and choose the best performing epoch as the final version of the model\n",
    "args = TrainingArguments(\n",
    "\teval_strategy = \"epoch\",\n",
    "\tsave_strategy = \"epoch\",\n",
    "    # save_total_limit = 5,\n",
    "\tlogging_strategy = \"epoch\",\n",
    "\tlearning_rate = lr,\n",
    "\tper_device_train_batch_size = batch_size,\n",
    "\tper_device_eval_batch_size = batch_size,\n",
    "\tnum_train_epochs = num_epochs,\n",
    "\tweight_decay = decay,\n",
    "\tload_best_model_at_end = True,\n",
    "\tmetric_for_best_model = metric_name,\n",
    "\tlogging_dir = logs_path,\n",
    "\toutput_dir = model_path,\n",
    "    warmup_steps=100,\n",
    "\t# use_mps_device = True,\n",
    "\t# use_cpu = False,\n",
    "\tlogging_steps = 1,\n",
    "\t# gradient_accumulation_steps=2,\n",
    "\thub_token = hg_token,\n",
    "\thub_model_id = \"raasikhk/carlos_bert_v2_2\",\n",
    "\tpush_to_hub=True,\n",
    ")\n",
    "\n",
    "import os\n",
    "from sklearn.metrics import f1_score, roc_auc_score, accuracy_score, confusion_matrix\n",
    "from transformers import EvalPrediction\n",
    "import torch\n",
    "from numpy import ndarray\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Tuple\n",
    "\n",
    "def get_next_image_number(directory: str) -> int:\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "        return 1\n",
    "    images = glob.glob(os.path.join(directory, '*.png'))\n",
    "    if not images:\n",
    "        return 1\n",
    "    numbers = [int(os.path.basename(image).split('_')[0]) for image in images]\n",
    "    return max(numbers) + 1\n",
    "\n",
    "def plot_confusion_matrix(cm, save_path, title):\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(cm))\n",
    "    plt.xticks(tick_marks, tick_marks, rotation=45)\n",
    "    plt.yticks(tick_marks, tick_marks)\n",
    "    \n",
    "    for i in range(len(cm)):\n",
    "        for j in range(len(cm[i])):\n",
    "            plt.text(j, i, format(cm[i, j], 'd'), horizontalalignment=\"center\", color=\"white\" if cm[i, j] > cm.max() / 2. else \"black\")\n",
    "    \n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path)\n",
    "    plt.close()\n",
    "\n",
    "def my_accuracy_score(y_true: np.ndarray, y_pred: np.ndarray) -> Tuple[int, int, int, int]:\n",
    "    directory = 'cm'\n",
    "    image_number = get_next_image_number(directory)\n",
    "    \n",
    "    labels = [\"Subjective\", \"Gender\", \"Jargon\", \"Social\"]\n",
    "    true_pos_list, false_pos_list, true_neg_list, false_neg_list = [], [], [], []\n",
    "\n",
    "    for i, label in enumerate(labels):\n",
    "        save_path = os.path.join(directory, f'{image_number}_{label}.png')\n",
    "        \n",
    "        # Calculate confusion matrix for the current label\n",
    "        cm = confusion_matrix(y_true[:, i], y_pred[:, i])\n",
    "        \n",
    "        # Plot confusion matrix\n",
    "        plot_confusion_matrix(cm, save_path, f'Confusion Matrix - {label}')\n",
    "        \n",
    "        # Calculate true positives, false positives, true negatives, false negatives\n",
    "        true_pos = np.sum((y_true[:, i] == 1) & (y_pred[:, i] == 1))\n",
    "        false_pos = np.sum((y_true[:, i] == 0) & (y_pred[:, i] == 1))\n",
    "        true_neg = np.sum((y_true[:, i] == 0) & (y_pred[:, i] == 0))\n",
    "        false_neg = np.sum((y_true[:, i] == 1) & (y_pred[:, i] == 0))\n",
    "        \n",
    "        true_pos_list.append(true_pos)\n",
    "        false_pos_list.append(false_pos)\n",
    "        true_neg_list.append(true_neg)\n",
    "        false_neg_list.append(false_neg)\n",
    "    \n",
    "    return (\n",
    "        sum(true_pos_list), sum(false_pos_list), \n",
    "        sum(true_neg_list), sum(false_neg_list)\n",
    "    )\n",
    "\n",
    "\n",
    "def partial_accuracy_score(y_true: ndarray, y_pred: ndarray):\n",
    "\tnum_objects = len(y_true)\n",
    "\tnum_labels = len(y_true)*4\n",
    "\tcorrect_predictions = 0\n",
    "\t\n",
    "\tfor i in range(num_objects):\n",
    "\t\tfor j in range(len(y_true[i])):\n",
    "\t\t\tif y_true[i][j] == y_pred[i][j]:\n",
    "\t\t\t\tcorrect_predictions += 1\n",
    "\t\n",
    "\taccuracy = correct_predictions / num_labels\n",
    "\treturn accuracy\n",
    "\n",
    "# source: https://jesusleal.io/2021/04/21/Longformer-multilabel-classification/\n",
    "def multi_label_metrics(predictions, labels, threshold=0.5):\n",
    "\t# first, apply sigmoid on predictions which are of shape (batch_size, num_labels)\n",
    "\tsigmoid = torch.nn.Sigmoid()\n",
    "\tprobs = sigmoid(torch.Tensor(predictions))\n",
    "\t# next, use threshold to turn them into integer predictions\n",
    "\ty_pred = np.zeros(probs.shape)\n",
    "\ty_pred[np.where(probs >= threshold)] = 1\n",
    "\t# finally, compute metrics\n",
    "\ty_true = labels\n",
    "\tf1_micro_average = f1_score(y_true=y_true, y_pred=y_pred, average='micro')\n",
    "\troc_auc = roc_auc_score(y_true, y_pred, average = 'micro')\n",
    "\taccuracy = accuracy_score(y_true, y_pred)\n",
    "\tmyacc = partial_accuracy_score(y_true, y_pred)\n",
    "\ttrue_pos, false_pos, true_neg, false_neg = my_accuracy_score(y_true, y_pred)\n",
    "\t# return as dictionary\n",
    "\tmetrics = {'f1': f1_micro_average,\n",
    "\t\t\t\t'roc_auc': roc_auc,\n",
    "\t\t\t\t'exact_match_acc': accuracy,\n",
    "\t\t\t\t\"partial_acc\": myacc,\n",
    "\t\t\t\t'true_pos': true_pos,\n",
    "        \t\t'true_neg': true_neg,\n",
    "        \t\t'false_neg': false_neg,\n",
    "\t\t\t\t'false_pos': false_pos}\n",
    "\treturn metrics\n",
    "\n",
    "def compute_metrics(p: EvalPrediction):\n",
    "\tpreds = p.predictions[0] if isinstance(p.predictions, \n",
    "\t\t\ttuple) else p.predictions\n",
    "\tresult = multi_label_metrics(\n",
    "\t\tpredictions=preds, \n",
    "\t\tlabels=p.label_ids)\n",
    "\treturn result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "\tmodel,\n",
    "\targs,\n",
    "\ttrain_dataset=encoded_dataset[\"train\"],\n",
    "\teval_dataset=encoded_dataset[\"validation\"],\n",
    "\ttokenizer=tokenizer,\n",
    "\tcompute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TrainOutput(global_step=5430, training_loss=0.039493819055855826, metrics={'train_runtime': 1080.8201, 'train_samples_per_second': 40.081, 'train_steps_per_second': 5.024, 'total_flos': 1.139817559375872e+16, 'train_loss': 0.039493819055855826, 'epoch': 30.0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{'eval_loss': 0.2363041341304779,\n",
    " 'eval_f1': 0.8076923076923078,\n",
    " 'eval_roc_auc': 0.8846526655896608,\n",
    " 'eval_exact_match_acc': 0.8232044198895028,\n",
    " 'eval_partial_acc': 0.9447513812154696,\n",
    " 'eval_true_pos': 84,\n",
    " 'eval_true_neg': 600,\n",
    " 'eval_false_neg': 21,\n",
    " 'eval_false_pos': 19,\n",
    " 'eval_runtime': 2.0471,\n",
    " 'eval_samples_per_second': 88.418,\n",
    " 'eval_steps_per_second': 11.235,\n",
    " 'epoch': 30.0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serving TensorBoard on localhost; to expose to the network, use a proxy or pass --bind_all\n",
      "TensorBoard 2.17.0 at http://localhost:6006/ (Press CTRL+C to quit)\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "# view logs (only needed for analysis)\n",
    "# !pip install tensorboard\n",
    "!tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save_pretrained(\"model\")\n",
    "# tokenizer.save_pretrained(\"tokenizer\")\n",
    "# tokenizer = transformers.BertTokenizer.from_pretrained(\"tokenizer\")\n",
    "# model = transformers.BertForSequenceClassification.from_pretrained(\"model/checkpoint-1200\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoding: {'input_ids': tensor([[  101,  2285,  2826,  2599,  1011,  1999,  2744,  2794,  1012,  2254,\n",
      "          2889,  6585,  2744,  2794,  1012,  4874, 11865,  4328, 11644,  1999,\n",
      "          2030,  4939,  1005,  1055, 18873, 11632,  2007,  6819,  9126,  2063,\n",
      "          1999,  2807,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "logits: tensor([[-7.2064, -6.6730,  4.9584, -7.1437]], grad_fn=<AddmmBackward0>)\n",
      "probs tensor([7.4127e-04, 1.2630e-03, 9.9302e-01, 7.8918e-04],\n",
      "       grad_fn=<SigmoidBackward0>)\n",
      "['Jargon']\n"
     ]
    }
   ],
   "source": [
    "# test a description\n",
    "text = \"December 1992 lead-in term added. January 1991 alternate term added. Object fumigated in Orkin's Piedmont vault with Vikane in 1994\"\n",
    "\n",
    "encoding = tokenizer(text, return_tensors=\"pt\")\n",
    "encoding = {k: v.to(trainer.model.device) for k,v in encoding.items()}\n",
    "print(f\"encoding: {encoding}\")\n",
    "\n",
    "outputs = trainer.model(**encoding)\n",
    "# print(f\"outputs: {outputs}\")\n",
    "\n",
    "logits = outputs.logits\n",
    "print(f\"logits: {logits}\")\n",
    "\n",
    "# apply sigmoid + threshold\n",
    "sigmoid = torch.nn.Sigmoid()\n",
    "probs = sigmoid(logits.squeeze().cpu())\n",
    "print(f\"probs: {probs}\")\n",
    "predictions = np.zeros(probs.shape)\n",
    "predictions[np.where(probs >= 0.5)] = 1\n",
    "# turn predicted id's into actual label names\n",
    "predicted_labels = [id2label[idx] for idx, label in enumerate(predictions) if label == 1.0]\n",
    "print(predicted_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PREDICTION**\n",
    "\n",
    "Run the first code block only if you have the model folder and have NOT done training above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------------------------------------------------\n",
    "-----------------------------------------------------------------------------\n",
    "-----------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: [{'label': 'Jargon', 'score': 0.9940457344055176}, {'label': 'Subjective', 'score': 0.9570311903953552}, {'label': 'Social', 'score': 0.0018877587281167507}, {'label': 'Gender', 'score': 0.001033065258525312}]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TEST THE MODEL\n",
    "# IF YOU DONT WANT TO TRAIN THEN LOAD MODEL FROM HUGGINGFACE\n",
    "\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TextClassificationPipeline\n",
    "import torch\n",
    "\n",
    "device = 0 if torch.cuda.is_available() else -1\n",
    "\n",
    "# if tokenizer == None:\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"raasikhk/carlos_bert_v2_2\", revision=\"4f6590dd149a1cf31d0cc09fa6e2db13fdfc15f1\")\n",
    "# if model == None:\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"raasikhk/carlos_bert_v2_2\", revision=\"4f6590dd149a1cf31d0cc09fa6e2db13fdfc15f1\", output_attentions=True)\n",
    "\n",
    "pipe = TextClassificationPipeline(model=model, tokenizer=tokenizer, top_k=None, truncation=True, padding=True, device=device)\n",
    "\n",
    "\"\"\"Sinker\n",
    "\n",
    "NOTE: UPDATED in June 2021 with information from 1984 accession worksheet.\n",
    "\n",
    "A February 14, 1997 file memo from registrar Lori Iliff discussed how sources and provenance were determined for objects that were believed to have an Etowah or Etowah-related provenance.  This memo did not discuss the X.0600-X.0697 numbered objects, as the sources and provenance of those objects had been discussed in a March 1990 memo.  Information regarding the objects in the 1997 memo came from the Accession Log I (green-blue colored ledger) and old accession sheets. According to Lori's memo it was unclear when the accession log was started, but it was on or prior to 1984.  The accession worksheets had been created in 1984.\n",
    "\n",
    "According to Lori's memo, the designation of Etowah as provenance and Phillips Academy as source on the accession worksheets seemed arbitrary and not based on prior museum records.  Therefore the designation of Etowah or Phillips Academy based solely on an accession worksheet may be suspect. Below is a summary of what was found for this object.\n",
    "\n",
    "X.0232.024 - According to the memo, the accession log lists no source, but lists Etowah as provenance.  The memo does not mention an accession worksheet. There is a 1984 accession worksheet in the object file.  It notes the provenance as Georgia, Etowah Mounds and does not note a source.\n",
    "\n",
    "The memos from the 1990s do not mention the \"Specimen Record\" worksheets housed in the blue fabric-covered binders. A few of these worksheets contain notes added by Lori Iliff in 1994.  It is unclear why these worksheets are not mentioned in the 1990s memos, but for completeness, their information is noted here.  It is however, unclear when these worksheets were created, by whom, and where the information in the worksheets came from.  Many have notes regarding packing objects for storage in 1982, so it can be assumed these were created in 1982 or earlier. There is one Specimen Record for X.0232.023, X.0232.024, X.0280.001, X.0280.002, X.0281 and X.0282.  The Specimen Record does not list a provenance, and W.H. Ferguson is listed as the source.\n",
    "\n",
    "The catalog for the 1982 \"A Preview of the Collections\"exhibition in Schatten Gallery lists the credit line for X.0232.024 as \"Gift of W.H. Ferguson\", but there is no indication as to where this information came from.\n",
    "\n",
    ".\n",
    "\n",
    "Luminescence induced by the absorption of infrared radiation, visible light, or ultraviolet radiation.  RHDEL2.\n",
    "\n",
    "Identified as Jasper by William Size.\"\"\"\n",
    "\n",
    "\n",
    "texts = [\"\"\"A Chewa boy in Malawi must undergo a three-day initiation in order to achieve full status as an adult. Masks, such as this one, may be commissioned from a recognized carver by a friend or relative, or by the initiate himself... The mischievous characters interact with and perform for the audience to teach moral lessons and enforce social norms. This extraordinary example is carved from a dense, oily hardwood and sparingly decorated with red European paint. Its commanding presence is marked by a strong brow, varying textures and materials in the beard, and a rather wild full head of hair.\"\"\"]\n",
    "\n",
    "# Make predictions\n",
    "predictions = pipe(texts)\n",
    "\n",
    "# Print the predictions\n",
    "for i, text in enumerate(texts):\n",
    "    # print(f\"Text: {text}\")\n",
    "    print(f\"Predictions: {predictions[i]}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make progressbar\n",
    "import sys\n",
    "def print_progress_bar(percentage):\n",
    "    bar_length = 40 \n",
    "    block = int(bar_length * (percentage / 100))\n",
    "    progress_bar = \"█\" * block + \" \" * (bar_length - block)\n",
    "    sys.stdout.write(f\"\\r[{progress_bar}] {percentage:.2f}%\")\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OPTIONS:\n",
      "unclean data = False\n",
      "testing set = test\n",
      "\n",
      "Getting data...\n",
      "Getting predictions...\n",
      "[████████████████████████████████████████] 100.00%\n",
      "\n",
      "Accuracy Calculations:\n",
      "ALL ACCURACY: 0.8333333333333334\n",
      "PARTIAL ACCURACY: 0.9444444444444444\n",
      "f1 score 0.7701149425287356\n"
     ]
    }
   ],
   "source": [
    "# CALCULATE ACCURACY\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TextClassificationPipeline\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "unclean = False # test on filtered descriptions or original, noisy ones\n",
    "\n",
    "test_on = \"validation\" # choose what to test on\n",
    "test_on = \"test\"\n",
    "\n",
    "print(\"OPTIONS:\")\n",
    "print(f\"unclean data = {unclean}\")\n",
    "print(f\"testing set = {test_on}\\n\")\n",
    "\n",
    "device = 0 if torch.cuda.is_available() else -1\n",
    "\n",
    "# model = AutoModelForSequenceClassification.from_pretrained(\"raasikhk/carlos_bert_v2_2\")\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"raasikhk/carlos_bert_v2_2\")\n",
    "\n",
    "pipe = TextClassificationPipeline(model=model, tokenizer=tokenizer, top_k=None, truncation=True, padding=True, device=device)\n",
    "\n",
    "print(\"Getting data...\")\n",
    "if unclean:\n",
    "\tunclean_df = pd.read_excel(\"../../../carlos_data/preprocessed_data_v3.xlsx\")\n",
    "\tunclean_df = unclean_df.drop(['Social', 'Jargon', 'Subjective', 'Gender'], axis=1)\n",
    "\n",
    "\t# Replace with test dataset\n",
    "\ttest_split = dataset[test_on]\n",
    "\ttest_split = pd.DataFrame(test_split)\n",
    "\ttest_split = test_split.drop(['Social', 'Jargon', 'Subjective', 'Gender'], axis=1)\n",
    "\n",
    "\t# Merge test_descriptions with unclean_df on ObjectID\n",
    "\tmerged_df = test_split.merge(unclean_df, on=\"ObjectID\", suffixes=('', '_unclean'), how='left')\n",
    "\tmerged_df.to_csv(\"~/Downloads/example.csv\")\n",
    "\t# Extract the newly replaced descriptions\n",
    "\tnew_descriptions = merged_df[\"TextEntry\"].values\n",
    "\n",
    "\t# Get list of unclean descriptions\n",
    "\ttest_descriptions = new_descriptions.tolist()\n",
    "else:\n",
    "    test_descriptions = dataset[test_on][\"Description\"]\n",
    "\n",
    "# make predictions variable of the format\n",
    "# -----------------------\n",
    "# bias1 bias2 bias3 bias4\n",
    "# -----------------------\n",
    "#  1     0     1     0\n",
    "#  0     1     0     1\n",
    "#  0     1     0     0\n",
    "# ...   ...   ...   ...\n",
    "predictions = np.zeros((len(test_descriptions), 4), int)\n",
    "\n",
    "print(\"Getting predictions...\")\n",
    "c = 0 # counter for progress bar\n",
    "for i in range(len(test_descriptions)):\n",
    "    pred = pipe(test_descriptions[i])\n",
    "    for j in range(4):\n",
    "        label = pred[0][j][\"label\"]\n",
    "        score = pred[0][j][\"score\"]\n",
    "        if label == \"Subjective\":\n",
    "            predictions[i][0] = 1 if score >= 0.5 else 0\n",
    "        elif label == \"Gender\":\n",
    "            predictions[i][1] = 1 if score >= 0.5 else 0\n",
    "        elif label == \"Jargon\":\n",
    "            predictions[i][2] = 1 if score >= 0.5 else 0\n",
    "        elif label == \"Social\":\n",
    "            predictions[i][3] = 1 if score >= 0.5 else 0\n",
    "    c += 1\n",
    "    print_progress_bar(c/len(test_descriptions)*100)\n",
    "\n",
    "# merge classifications of each bias column wise to create matrix:\n",
    "# subj0   gend0   jarg0   soci0\n",
    "# subj0   gend0   jarg0   soci0\n",
    "# subj0   gend0   jarg0   soci0\n",
    "true_values = np.column_stack((dataset[test_on][\"Subjective\"], dataset[test_on][\"Gender\"], \n",
    "                               dataset[test_on][\"Jargon\"], dataset[test_on][\"Social\"]))\n",
    "\n",
    "print(\"\\n\\nAccuracy Calculations:\")\n",
    "# Use Scikit-learn method\n",
    "print(f\"Accuracy: {accuracy_score(true_values, predictions)}\")\n",
    "\n",
    "# Calculate partial accuracy\n",
    "part_acc_score = 0\n",
    "total = true_values.size  # Or predictions.size, since both have the same shape\n",
    "\n",
    "for i in range(true_values.shape[0]):\n",
    "    for j in range(true_values.shape[1]):\n",
    "        if true_values[i][j] == predictions[i][j]:\n",
    "            part_acc_score += 1\n",
    "\n",
    "print(f\"Partial Accuracy: {part_acc_score/total}\")\n",
    "print(f\"F1 Score: {f1_score(true_values, predictions, average='micro')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Subjective': 0.95, 'Gender': 0.9777777777777777, 'Jargon': 0.8944444444444445, 'Social': 0.9555555555555556}\n"
     ]
    }
   ],
   "source": [
    "# Get accuracy per label\n",
    "import numpy as np\n",
    "\n",
    "def calculate_accuracy_per_label(predictions, true_values):\n",
    "    accuracies = {}\n",
    "    labels = [\"Subjective\", \"Gender\", \"Jargon\", \"Social\"]\n",
    "    \n",
    "    for i, label in enumerate(labels):\n",
    "        correct_predictions = np.sum(predictions[:, i] == true_values[:, i])\n",
    "        total_predictions = predictions.shape[0]\n",
    "        accuracy = correct_predictions / total_predictions\n",
    "        accuracies[label] = accuracy\n",
    "\n",
    "    return accuracies\n",
    "\n",
    "# Example usage\n",
    "accuracies = calculate_accuracy_per_label(predictions, true_values)\n",
    "print(accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     ObjectID                                FilteredDescription  Subjective  \\\n",
      "0         102  Pottery Fragment (Body) Provenance taken from ...           0   \n",
      "1       14331  Jug Fragment April 1993 guide term moved. Brow...           0   \n",
      "2       20623  Flat Bottomed Bowl with Twisted Applique Desig...           0   \n",
      "3         612  A February 14, 1997 file memo from registrar L...           0   \n",
      "4        1466  Arrowhead No provenance information in files. ...           0   \n",
      "..        ...                                                ...         ...   \n",
      "175     20157  May 1993 scope note changed. Sideboards, espec...           0   \n",
      "176     17587                         Interno di San Paolo, Roma           0   \n",
      "177      2279  Coin September 1995 guide term changed, was <E...           0   \n",
      "178      2187  Flakes (33) Objects in Lot 11: 1963.067.013 19...           0   \n",
      "179      5978  A February 14, 1997 file memo from registrar L...           0   \n",
      "\n",
      "     Gender  Jargon  Social  \n",
      "0         0       0       0  \n",
      "1         0       0       0  \n",
      "2         0       0       0  \n",
      "3         0       1       0  \n",
      "4         0       0       0  \n",
      "..      ...     ...     ...  \n",
      "175       0       1       0  \n",
      "176       0       1       0  \n",
      "177       0       0       0  \n",
      "178       0       0       0  \n",
      "179       0       1       0  \n",
      "\n",
      "[180 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "# save predictions for validation or test set (depending on choice above) as csv\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(predictions, columns=[\"Subjective\", \"Gender\", \"Jargon\", \"Social\"])\n",
    "\n",
    "# Add the descriptions as the first column (choose unclean in block above)\n",
    "if unclean:\n",
    "\tdf.insert(0, \"Description\", test_descriptions)\n",
    "else:\n",
    "\tdf.insert(0, \"FilteredDescription\", test_descriptions)\n",
    "\n",
    "# add objectID\n",
    "df.insert(0, \"ObjectID\", dataset[test_on][\"ObjectID\"])\n",
    "\n",
    "df.to_csv(f\"../../../carlos_data/predicted_data/bert_v2_2_{test_on}_predictions.csv\", index=False)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmenting descriptions...\n",
      "Getting predictions...\n",
      "[███                                     ] 8.89%"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[124], line 102\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGetting predictions...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(test_descriptions)):\n\u001b[0;32m--> 102\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[43mget_prediction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_descriptions_segmented\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    103\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m j, bias \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(biases):\n\u001b[1;32m    104\u001b[0m         predictions[i, j] \u001b[38;5;241m=\u001b[39m pred[bias]\n",
      "Cell \u001b[0;32mIn[124], line 57\u001b[0m, in \u001b[0;36mget_prediction\u001b[0;34m(sentences)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(sentences)):\n\u001b[1;32m     56\u001b[0m     sentence \u001b[38;5;241m=\u001b[39m sentences[i]\n\u001b[0;32m---> 57\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[43mpipe\u001b[49m\u001b[43m(\u001b[49m\u001b[43msentence\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     58\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m4\u001b[39m):\n\u001b[1;32m     59\u001b[0m         label \u001b[38;5;241m=\u001b[39m pred[\u001b[38;5;241m0\u001b[39m][j][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/Documents/Coding/ai.xperience/carlos-artifact-tagging-bias/myenv/lib/python3.11/site-packages/transformers/pipelines/text_classification.py:156\u001b[0m, in \u001b[0;36mTextClassificationPipeline.__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;124;03mClassify the text(s) given as inputs.\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;124;03m    If `top_k` is used, one such dictionary is returned per label.\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    155\u001b[0m inputs \u001b[38;5;241m=\u001b[39m (inputs,)\n\u001b[0;32m--> 156\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;66;03m# TODO try and retrieve it in a nicer way from _sanitize_parameters.\u001b[39;00m\n\u001b[1;32m    158\u001b[0m _legacy \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop_k\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m kwargs\n",
      "File \u001b[0;32m~/Documents/Coding/ai.xperience/carlos-artifact-tagging-bias/myenv/lib/python3.11/site-packages/transformers/pipelines/base.py:1254\u001b[0m, in \u001b[0;36mPipeline.__call__\u001b[0;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1246\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mnext\u001b[39m(\n\u001b[1;32m   1247\u001b[0m         \u001b[38;5;28miter\u001b[39m(\n\u001b[1;32m   1248\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_iterator(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1251\u001b[0m         )\n\u001b[1;32m   1252\u001b[0m     )\n\u001b[1;32m   1253\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1254\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_single\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreprocess_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforward_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpostprocess_params\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Coding/ai.xperience/carlos-artifact-tagging-bias/myenv/lib/python3.11/site-packages/transformers/pipelines/base.py:1261\u001b[0m, in \u001b[0;36mPipeline.run_single\u001b[0;34m(self, inputs, preprocess_params, forward_params, postprocess_params)\u001b[0m\n\u001b[1;32m   1259\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_single\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs, preprocess_params, forward_params, postprocess_params):\n\u001b[1;32m   1260\u001b[0m     model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocess(inputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpreprocess_params)\n\u001b[0;32m-> 1261\u001b[0m     model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mforward_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1262\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpostprocess(model_outputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpostprocess_params)\n\u001b[1;32m   1263\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[0;32m~/Documents/Coding/ai.xperience/carlos-artifact-tagging-bias/myenv/lib/python3.11/site-packages/transformers/pipelines/base.py:1161\u001b[0m, in \u001b[0;36mPipeline.forward\u001b[0;34m(self, model_inputs, **forward_params)\u001b[0m\n\u001b[1;32m   1159\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m inference_context():\n\u001b[1;32m   1160\u001b[0m         model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_tensor_on_device(model_inputs, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m-> 1161\u001b[0m         model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mforward_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1162\u001b[0m         model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_tensor_on_device(model_outputs, device\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m   1163\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/Documents/Coding/ai.xperience/carlos-artifact-tagging-bias/myenv/lib/python3.11/site-packages/transformers/pipelines/text_classification.py:187\u001b[0m, in \u001b[0;36mTextClassificationPipeline._forward\u001b[0;34m(self, model_inputs)\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse_cache\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39msignature(model_forward)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    186\u001b[0m     model_inputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse_cache\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 187\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Coding/ai.xperience/carlos-artifact-tagging-bias/myenv/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Coding/ai.xperience/carlos-artifact-tagging-bias/myenv/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/Coding/ai.xperience/carlos-artifact-tagging-bias/myenv/lib/python3.11/site-packages/transformers/models/bert/modeling_bert.py:1695\u001b[0m, in \u001b[0;36mBertForSequenceClassification.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1687\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1688\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[1;32m   1689\u001b[0m \u001b[38;5;124;03m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001b[39;00m\n\u001b[1;32m   1690\u001b[0m \u001b[38;5;124;03m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001b[39;00m\n\u001b[1;32m   1691\u001b[0m \u001b[38;5;124;03m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[1;32m   1692\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1693\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[0;32m-> 1695\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1696\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1697\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1698\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1699\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1700\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1701\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1702\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1703\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1704\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1705\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1707\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   1709\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(pooled_output)\n",
      "File \u001b[0;32m~/Documents/Coding/ai.xperience/carlos-artifact-tagging-bias/myenv/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Coding/ai.xperience/carlos-artifact-tagging-bias/myenv/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/Coding/ai.xperience/carlos-artifact-tagging-bias/myenv/lib/python3.11/site-packages/transformers/models/bert/modeling_bert.py:1141\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1134\u001b[0m \u001b[38;5;66;03m# Prepare head mask if needed\u001b[39;00m\n\u001b[1;32m   1135\u001b[0m \u001b[38;5;66;03m# 1.0 in head_mask indicate we keep the head\u001b[39;00m\n\u001b[1;32m   1136\u001b[0m \u001b[38;5;66;03m# attention_probs has shape bsz x n_heads x N x N\u001b[39;00m\n\u001b[1;32m   1137\u001b[0m \u001b[38;5;66;03m# input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]\u001b[39;00m\n\u001b[1;32m   1138\u001b[0m \u001b[38;5;66;03m# and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]\u001b[39;00m\n\u001b[1;32m   1139\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[0;32m-> 1141\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1142\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1143\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1144\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1145\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1146\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1147\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1148\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1149\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1150\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1151\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1152\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1153\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1154\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/Coding/ai.xperience/carlos-artifact-tagging-bias/myenv/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Coding/ai.xperience/carlos-artifact-tagging-bias/myenv/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/Coding/ai.xperience/carlos-artifact-tagging-bias/myenv/lib/python3.11/site-packages/transformers/models/bert/modeling_bert.py:694\u001b[0m, in \u001b[0;36mBertEncoder.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    683\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    684\u001b[0m         layer_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m    685\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    691\u001b[0m         output_attentions,\n\u001b[1;32m    692\u001b[0m     )\n\u001b[1;32m    693\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 694\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    695\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    696\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    697\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    698\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    699\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    700\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    701\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    702\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    704\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    705\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m~/Documents/Coding/ai.xperience/carlos-artifact-tagging-bias/myenv/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Coding/ai.xperience/carlos-artifact-tagging-bias/myenv/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/Coding/ai.xperience/carlos-artifact-tagging-bias/myenv/lib/python3.11/site-packages/transformers/models/bert/modeling_bert.py:626\u001b[0m, in \u001b[0;36mBertLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    623\u001b[0m     cross_attn_present_key_value \u001b[38;5;241m=\u001b[39m cross_attention_outputs[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    624\u001b[0m     present_key_value \u001b[38;5;241m=\u001b[39m present_key_value \u001b[38;5;241m+\u001b[39m cross_attn_present_key_value\n\u001b[0;32m--> 626\u001b[0m layer_output \u001b[38;5;241m=\u001b[39m \u001b[43mapply_chunking_to_forward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    627\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeed_forward_chunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchunk_size_feed_forward\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mseq_len_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_output\u001b[49m\n\u001b[1;32m    628\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    629\u001b[0m outputs \u001b[38;5;241m=\u001b[39m (layer_output,) \u001b[38;5;241m+\u001b[39m outputs\n\u001b[1;32m    631\u001b[0m \u001b[38;5;66;03m# if decoder, return the attn key/values as the last output\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/Coding/ai.xperience/carlos-artifact-tagging-bias/myenv/lib/python3.11/site-packages/transformers/pytorch_utils.py:238\u001b[0m, in \u001b[0;36mapply_chunking_to_forward\u001b[0;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;66;03m# concatenate output at same dimension\u001b[39;00m\n\u001b[1;32m    236\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcat(output_chunks, dim\u001b[38;5;241m=\u001b[39mchunk_dim)\n\u001b[0;32m--> 238\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minput_tensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Coding/ai.xperience/carlos-artifact-tagging-bias/myenv/lib/python3.11/site-packages/transformers/models/bert/modeling_bert.py:639\u001b[0m, in \u001b[0;36mBertLayer.feed_forward_chunk\u001b[0;34m(self, attention_output)\u001b[0m\n\u001b[1;32m    637\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfeed_forward_chunk\u001b[39m(\u001b[38;5;28mself\u001b[39m, attention_output):\n\u001b[1;32m    638\u001b[0m     intermediate_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintermediate(attention_output)\n\u001b[0;32m--> 639\u001b[0m     layer_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput\u001b[49m\u001b[43m(\u001b[49m\u001b[43mintermediate_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    640\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m layer_output\n",
      "File \u001b[0;32m~/Documents/Coding/ai.xperience/carlos-artifact-tagging-bias/myenv/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Coding/ai.xperience/carlos-artifact-tagging-bias/myenv/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/Coding/ai.xperience/carlos-artifact-tagging-bias/myenv/lib/python3.11/site-packages/transformers/models/bert/modeling_bert.py:551\u001b[0m, in \u001b[0;36mBertOutput.forward\u001b[0;34m(self, hidden_states, input_tensor)\u001b[0m\n\u001b[1;32m    550\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor, input_tensor: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[0;32m--> 551\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdense\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    552\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(hidden_states)\n\u001b[1;32m    553\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mLayerNorm(hidden_states \u001b[38;5;241m+\u001b[39m input_tensor)\n",
      "File \u001b[0;32m~/Documents/Coding/ai.xperience/carlos-artifact-tagging-bias/myenv/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Coding/ai.xperience/carlos-artifact-tagging-bias/myenv/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/Coding/ai.xperience/carlos-artifact-tagging-bias/myenv/lib/python3.11/site-packages/torch/nn/modules/linear.py:116\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# accuracy score using bert looking at descriptions line by line\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TextClassificationPipeline\n",
    "import torch\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# CHOOSE THESE PARAMETERS\n",
    "unclean = False # test on noisy descs\n",
    "test_on = \"validation\" # choose what to test on\n",
    "test_on = \"test\"\n",
    "\n",
    "device = 0 if torch.cuda.is_available() else -1\n",
    "\n",
    "# model = AutoModelForSequenceClassification.from_pretrained(\"raasikhk/carlos_bert_v2_2\")\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"raasikhk/carlos_bert_v2_2\")\n",
    "\n",
    "pipe = TextClassificationPipeline(model=model, tokenizer=tokenizer, top_k=None, truncation=True, padding=True, device=device)\n",
    "\n",
    "if unclean:\n",
    "\tunclean_df = pd.read_excel(\"../../../carlos_data/preprocessed_data_v3.xlsx\")\n",
    "\tunclean_df = unclean_df.drop(['Social', 'Jargon', 'Subjective', 'Gender'], axis=1)\n",
    "\n",
    "\t# Replace with test dataset\n",
    "\ttest_split = dataset[test_on]\n",
    "\ttest_split = pd.DataFrame(test_split)\n",
    "\ttest_split = test_split.drop(['Social', 'Jargon', 'Subjective', 'Gender'], axis=1)\n",
    "\n",
    "\t# Merge test_descriptions with unclean_df on ObjectID\n",
    "\tmerged_df = test_split.merge(unclean_df, on=\"ObjectID\", suffixes=('', '_unclean'), how='left')\n",
    "\n",
    "\t# Extract the newly replaced descriptions\n",
    "\tnew_descriptions = merged_df[\"TextEntry\"].values\n",
    "\n",
    "\t# Get list of unclean descriptions\n",
    "\ttest_descriptions = new_descriptions.tolist()\n",
    "else:\n",
    "    test_descriptions = dataset[test_on][\"Description\"]\n",
    "\n",
    "# segment test descriptions\n",
    "import pysbd\n",
    "seg = pysbd.Segmenter(language=\"en\", clean=False)\n",
    "\n",
    "# Segment each description into sentences and strip each sentence\n",
    "test_descriptions_segmented = []\n",
    "print(\"Segmenting descriptions...\")\n",
    "for desc in test_descriptions:\n",
    "    sentences = seg.segment(desc)\n",
    "    #sentences = desc.split(\"\\n\\n\")\n",
    "    stripped_sentences = [sentence.strip() for sentence in sentences]\n",
    "    test_descriptions_segmented.append(stripped_sentences)\n",
    "\n",
    "# this function gets a prediction for a description given an array of sentences in one description\n",
    "def get_prediction(sentences):\n",
    "    sentence_preds = np.zeros((len(sentences), 4), int)\n",
    "    for i in range(len(sentences)):\n",
    "        sentence = sentences[i]\n",
    "        pred = pipe(sentence)\n",
    "        for j in range(4):\n",
    "            label = pred[0][j][\"label\"]\n",
    "            score = pred[0][j][\"score\"]\n",
    "            if label == \"Subjective\":\n",
    "                sentence_preds[i][0] = 1 if score >= 0.5 else 0\n",
    "            elif label == \"Gender\":\n",
    "                sentence_preds[i][1] = 1 if score >= 0.5 else 0\n",
    "            elif label == \"Jargon\":\n",
    "                sentence_preds[i][2] = 1 if score >= 0.5 else 0\n",
    "            elif label == \"Social\":\n",
    "                sentence_preds[i][3] = 1 if score >= 0.5 else 0\n",
    "\n",
    "    result = {\"Subjective\": 0, \"Gender\": 0, \"Jargon\": 0, \"Social\": 0}\n",
    "    jargon_count=0\n",
    "    for row in sentence_preds:\n",
    "        for i, value in enumerate(row):\n",
    "            if value == 1:\n",
    "                if i == 0:\n",
    "                    result[\"Subjective\"] = 1\n",
    "                elif i == 1:\n",
    "                    result[\"Gender\"] = 1\n",
    "                elif i == 2:\n",
    "                    # jargon_count+=1\n",
    "                    # if jargon_count >= len(sentences):  \n",
    "                    #     print(f\"{jargon_count} >= {len(sentences)}\")              \n",
    "                    #     result[\"Jargon\"] = 1\n",
    "                    result[\"Jargon\"] = 1\n",
    "                elif i == 3:\n",
    "                    result[\"Social\"] = 1\n",
    "    return result\n",
    "\n",
    "# make predictions variable of the format\n",
    "# -----------------------\n",
    "# bias1 bias2 bias3 bias4\n",
    "# -----------------------\n",
    "#   1     0     1     0\n",
    "#   0     1     0     1\n",
    "#   0     1     0     0\n",
    "# ...   ...   ...   ...\n",
    "predictions = np.zeros((len(test_descriptions), 4), int)\n",
    "biases = [\"Subjective\", \"Gender\", \"Jargon\", \"Social\"]\n",
    "\n",
    "print(\"Getting predictions...\")\n",
    "for i in range(len(test_descriptions)):\n",
    "    pred = get_prediction(test_descriptions_segmented[i])\n",
    "    for j, bias in enumerate(biases):\n",
    "        predictions[i, j] = pred[bias]\n",
    "    print_progress_bar(i/len(test_descriptions)*100)\n",
    "\n",
    "# merge classifications of each bias column wise to create matrix:\n",
    "# subj0   gend0   jarg0   soci0\n",
    "# subj0   gend0   jarg0   soci0\n",
    "# subj0   gend0   jarg0   soci0\n",
    "true_values = np.column_stack((dataset[test_on][\"Subjective\"], dataset[test_on][\"Gender\"], \n",
    "                               dataset[test_on][\"Jargon\"], dataset[test_on][\"Social\"]))\n",
    "\n",
    "# Use Scikit-learn method\n",
    "print(f\"\\nALL ACCURACY: {accuracy_score(true_values, predictions)}\")\n",
    "\n",
    "# Calculate partial accuracy\n",
    "part_acc_score = 0\n",
    "total = true_values.size  # Or predictions.size, since both have the same shape\n",
    "\n",
    "for i in range(true_values.shape[0]):\n",
    "    for j in range(true_values.shape[1]):\n",
    "        if true_values[i][j] == predictions[i][j]:\n",
    "            part_acc_score += 1\n",
    "\n",
    "print(f\"PARTIAL ACCURACY: {part_acc_score/total}\")\n",
    "\n",
    "print(f\"f1_score: {f1_score(true_values, predictions, average='micro')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize list to store confusion matrices for each label\n",
    "confusion_matrices = []\n",
    "\n",
    "# Iterate over each label (column in the matrices)\n",
    "for i in range(true_values.shape[1]):\n",
    "    # Compute confusion matrix for the current label\n",
    "    cm = confusion_matrix(true_values[:, i], predictions[:, i])\n",
    "    confusion_matrices.append(cm)\n",
    "\n",
    "# Print confusion matrices for each label\n",
    "for i, cm in enumerate(confusion_matrices):\n",
    "    print(f\"Confusion Matrix for Label {i}:\")\n",
    "    print(cm)\n",
    "    print()\n",
    "\n",
    "    # Optional: Plot the confusion matrix\n",
    "    plt.figure(figsize=(5, 4))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title(f'Confusion Matrix for Label {i}')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load pre-trained model and tokenizer\n",
    "\n",
    "# Example text\n",
    "text = \"The quick brown fox jumps over the lazy dog\"\n",
    "\n",
    "# Tokenize and prepare input\n",
    "inputs = tokenizer(text, return_tensors='pt')\n",
    "input_ids = inputs['input_ids']\n",
    "attention_mask = inputs['attention_mask']\n",
    "\n",
    "# Forward pass with attention output\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "attentions = outputs.attentions  # List of attention scores for each layer\n",
    "\n",
    "# Function to visualize attention for the last layer\n",
    "def visualize_attention(attentions, input_ids, tokenizer, layer_idx=-1):\n",
    "    attention = attentions[layer_idx].squeeze().detach().numpy()  # Get attention scores for the specified layer\n",
    "    # Token mapping\n",
    "    tokens = tokenizer.convert_ids_to_tokens(input_ids.squeeze().tolist())\n",
    "    \n",
    "    # Plot attention for the first attention head in the layer\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    sns.heatmap(attention[0], xticklabels=tokens, yticklabels=tokens, cmap='viridis')\n",
    "    plt.title(f'Attention Map - Layer {layer_idx + 1}')\n",
    "    plt.xlabel('Token')\n",
    "    plt.ylabel('Token')\n",
    "    plt.show()\n",
    "\n",
    "# Visualize attention for the last layer\n",
    "visualize_attention(attentions, input_ids, tokenizer, layer_idx=-1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
